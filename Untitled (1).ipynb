{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip caltech101.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv caltech-101 caltech101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 101])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define your custom VGG architecture\n",
    "class VGGCustom(nn.Module):\n",
    "    def __init__(self, num_classes=101):\n",
    "        super(VGGCustom, self).__init__()\n",
    "        # Load the pretrained VGG16_bn model with updated weights parameter\n",
    "        vgg16_bn = models.vgg16_bn(pretrained=True)\n",
    "        \n",
    "        # Extract the features and avgpool layers\n",
    "        self.features = vgg16_bn.features\n",
    "        self.avgpool = vgg16_bn.avgpool\n",
    "        \n",
    "        # Extract the classifier and replace only the last FC layer\n",
    "        self.classifier = vgg16_bn.classifier\n",
    "        in_features = self.classifier[-1].in_features\n",
    "        self.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x, is_feat=False, is_feats=False):\n",
    "        if is_feats:\n",
    "            # Extract intermediate features\n",
    "            f0 = self.features[:6](x)\n",
    "            f1 = self.features[6:13](f0)\n",
    "            f2 = self.features[13:23](f1)\n",
    "            f3 = self.features[23:33](f2)\n",
    "            f4 = self.features[33:43](f3)\n",
    "            f5 = self.features[43:](f4)\n",
    "            x = self.features[43:](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            f5 = x\n",
    "            out = self.classifier(x)\n",
    "            return out, [f0, f1, f2, f3, f4, f5]\n",
    "        else:\n",
    "            out = self.features(x)\n",
    "            feat = out.view(out.size(0), -1)\n",
    "            out = self.classifier(feat)\n",
    "            if is_feat:\n",
    "                return out, feat\n",
    "            else:\n",
    "                return out\n",
    "\n",
    "def get_modified_vgg16(num_classes=101):\n",
    "    return VGGCustom(num_classes=num_classes)\n",
    "\n",
    "def print_model_parameters(model):\n",
    "    total_params = 0\n",
    "    print(\"\\nModel Parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        param_count = param.numel()\n",
    "        print(f\"{name}: {param_count} parameters\")\n",
    "        total_params += param_count\n",
    "    print(f\"\\nTotal parameters: {total_params}\\n\")\n",
    "\n",
    "# Example usage for debugging:\n",
    "if __name__ == \"__main__\":\n",
    "    num_classes = 101\n",
    "    model = get_modified_vgg16(num_classes)\n",
    "    # Print number of parameters\n",
    "    #print_model_parameters(model)\n",
    "    \n",
    "    # Display model architecture\n",
    "    #print(model)\n",
    "    \n",
    "    # Dummy input for testing\n",
    "    x = torch.randn(2, 3, 224, 224)\n",
    "    \n",
    "    # Forward pass to check for errors\n",
    "    try:\n",
    "        output = model(x)\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during forward pass: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8874f6fc20246f4824d66361e9f5cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=32342954.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.7143, -0.2113,  0.1869, -0.0511,  0.5082,  0.1609,  0.1325, -0.3012,\n",
      "         -0.6604, -0.6724,  0.1985,  0.1130, -0.0930, -0.2193, -0.1445,  0.1166,\n",
      "          0.2685, -0.7260,  0.2278, -0.3078, -0.0468, -0.5321,  0.3160,  0.5961,\n",
      "         -0.4607,  0.1617, -0.1623, -0.3346,  0.0350,  0.2477, -0.2741,  0.5533,\n",
      "          0.0541,  0.6958, -0.3087,  0.6152, -0.7198,  0.2365, -0.5097, -0.3286,\n",
      "         -0.0379,  0.0367,  0.2030,  0.2758,  0.3033, -0.6011,  0.0591, -0.2044,\n",
      "         -0.0094, -0.0342,  0.0351, -0.1364,  0.0930,  0.6178,  0.0545, -0.3455,\n",
      "         -0.1983,  0.3619, -0.4687,  0.0285, -0.5291,  0.3501, -0.1526,  0.3591,\n",
      "         -0.4158,  0.2303, -0.0273, -0.0944, -0.1547, -0.2762, -0.1584, -0.5483,\n",
      "         -0.0165,  0.4406, -0.4021,  0.2026, -0.0141,  0.1389, -0.4394,  0.6808,\n",
      "         -0.2856,  0.3761,  0.4559, -0.1127, -0.4253,  0.1217,  0.3266,  0.5846,\n",
      "         -0.2218, -0.2434,  0.0762,  0.4013,  0.0187,  0.2633, -0.0765, -0.0402,\n",
      "         -0.2982,  0.0018,  0.1247, -0.1689,  0.1936]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "'''DenseNet in PyTorch.'''\n",
    "import math\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.densenet.children())[:-1])\n",
    "        # Replace the classifier with a new one for the desired number of classes\n",
    "        num_ftrs = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #out = self.features(x) \n",
    "        #out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        #out = self.densenet.classifier(out)\n",
    "        return self.densenet(x)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = DenseNet(num_classes=101)\n",
    "    x = torch.randn(1,3,224,224)\n",
    "    y = net(x)\n",
    "    #print(net)\n",
    "    print(y)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense = DenseNet(num_classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "Dense = nn.DataParallel(Dense)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/workspace/AL/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "            'net': Dense.state_dict(),\n",
    "            'acc': 0,\n",
    "            'epoch': 0,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "torch.save(state, os.path.join(checkpoint_path, 'rotation.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGGCustom(num_classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "vgg_model1 = nn.DataParallel(vgg_model)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/workspace/BAL/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "            'net': vgg_model1.state_dict(),\n",
    "            'acc': 0,\n",
    "            'epoch': 0,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "torch.save(state, os.path.join(checkpoint_path, 'rotation.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.8.0a0+1606899\n",
      "CUDA version: 11.1\n",
      "cuDNN version: 8005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. No GPUs detected.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs: {num_gpus}\")\n",
    "\n",
    "    # Optional: Print the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPUs detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
